{
  "integrations_researched": [
    {
      "name": "graphiti-core",
      "type": "library",
      "verified_package": {
        "name": "graphiti-core",
        "install_command": "pip install graphiti-core[falkordb,anthropic]",
        "version": ">=0.24.1",
        "verified": true,
        "extras_available": ["anthropic", "falkordb", "google-genai", "groq", "voyageai", "sentence-transformers", "neo4j-opensearch", "neptune", "kuzu", "dev", "tracing"]
      },
      "api_patterns": {
        "imports": {
          "core": [
            "from graphiti_core import Graphiti",
            "from graphiti_core.driver.falkordb_driver import FalkorDriver"
          ],
          "llm_clients": [
            "from graphiti_core.llm_client.openai_client import OpenAIClient",
            "from graphiti_core.llm_client.anthropic_client import AnthropicClient",
            "from graphiti_core.llm_client.azure_openai_client import AzureOpenAILLMClient",
            "from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient",
            "from graphiti_core.llm_client.config import LLMConfig"
          ],
          "embedders": [
            "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig",
            "from graphiti_core.embedder.azure_openai import AzureOpenAIEmbedderClient",
            "from graphiti_core.embedder.voyage import VoyageEmbedder, VoyageAIConfig"
          ],
          "cross_encoders": [
            "from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient"
          ]
        },
        "initialization": {
          "with_driver": "graphiti = Graphiti(graph_driver=driver, llm_client=llm_client, embedder=embedder)",
          "legacy_neo4j": "graphiti = Graphiti('bolt://localhost:7687', 'neo4j', 'password', llm_client=llm_client, embedder=embedder)"
        },
        "key_functions": [
          "Graphiti(graph_driver, llm_client, embedder)",
          "await graphiti.build_indices_and_constraints()",
          "await graphiti.add_episode(name, episode_body, source, source_description, reference_time, group_id)",
          "await graphiti.search(query, group_ids, num_results)",
          "await graphiti.close()"
        ],
        "verified_against": "Context7 MCP: /getzep/graphiti, /websites/help_getzep_graphiti"
      },
      "configuration": {
        "env_vars": [
          "OPENAI_API_KEY (default provider)",
          "ANTHROPIC_API_KEY (for Anthropic LLM)",
          "VOYAGE_API_KEY (for Voyage embeddings)"
        ],
        "config_classes": {
          "LLMConfig": {
            "fields": ["api_key", "model", "small_model", "base_url"],
            "usage": "LLMConfig(api_key='...', model='claude-sonnet-4-20250514', small_model='claude-3-5-haiku-20241022')"
          },
          "OpenAIEmbedderConfig": {
            "fields": ["api_key", "embedding_model", "embedding_dim", "base_url"],
            "usage": "OpenAIEmbedderConfig(api_key='...', embedding_model='text-embedding-3-small')"
          },
          "VoyageAIConfig": {
            "fields": ["api_key", "embedding_model"],
            "usage": "VoyageAIConfig(api_key='...', embedding_model='voyage-3')"
          }
        },
        "dependencies": ["openai (for Azure/Ollama compatibility)", "voyageai (optional)"]
      },
      "gotchas": [
        "For Ollama, use OpenAIGenericClient or OpenAIClient with base_url, NOT a dedicated Ollama client",
        "For Ollama, a dummy API key like 'ollama' is required even though Ollama doesn't validate it",
        "Azure OpenAI requires the /openai/v1/ suffix on the base_url",
        "Voyage embeddings require separate voyageai pip install: pip install graphiti-core[voyageai]",
        "Cross-encoder/reranker is optional but improves search quality",
        "FalkorDB default port is 6379, but project uses 6380"
      ],
      "research_sources": [
        "Context7 MCP: /getzep/graphiti",
        "Context7 MCP: /websites/help_getzep_graphiti",
        "https://pypi.org/project/graphiti-core/",
        "https://github.com/getzep/graphiti"
      ]
    },
    {
      "name": "Anthropic LLM Provider",
      "type": "library_integration",
      "verified_package": {
        "name": "graphiti-core[anthropic]",
        "install_command": "pip install graphiti-core[anthropic]",
        "version": "included with graphiti-core",
        "verified": true
      },
      "api_patterns": {
        "imports": [
          "from graphiti_core.llm_client.anthropic_client import AnthropicClient",
          "from graphiti_core.llm_client.config import LLMConfig"
        ],
        "initialization": "llm_client = AnthropicClient(config=LLMConfig(api_key='sk-ant-...', model='claude-sonnet-4-20250514', small_model='claude-3-5-haiku-20241022'))",
        "key_functions": [
          "AnthropicClient(config=LLMConfig(...))"
        ],
        "verified_against": "Context7 MCP: /websites/help_getzep_graphiti"
      },
      "configuration": {
        "env_vars": ["ANTHROPIC_API_KEY"],
        "models_supported": [
          "claude-sonnet-4-20250514",
          "claude-opus-4-20250514",
          "claude-3-5-haiku-20241022",
          "claude-sonnet-4-5-latest"
        ]
      },
      "gotchas": [
        "IMPORTANT: Anthropic does NOT provide embedding models - must use another provider for embeddings",
        "Anthropic officially recommends Voyage AI for embeddings",
        "The LLMConfig requires both 'model' and 'small_model' parameters",
        "The api_key can be passed in LLMConfig or via ANTHROPIC_API_KEY env var"
      ],
      "research_sources": [
        "Context7 MCP: /websites/help_getzep_graphiti",
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings"
      ]
    },
    {
      "name": "Azure OpenAI Provider",
      "type": "library_integration",
      "verified_package": {
        "name": "graphiti-core (base package)",
        "install_command": "pip install graphiti-core",
        "version": "included with graphiti-core",
        "verified": true,
        "additional_dependency": "openai (AsyncOpenAI client)"
      },
      "api_patterns": {
        "imports": [
          "from openai import AsyncOpenAI",
          "from graphiti_core.llm_client.azure_openai_client import AzureOpenAILLMClient",
          "from graphiti_core.llm_client.config import LLMConfig",
          "from graphiti_core.embedder.azure_openai import AzureOpenAIEmbedderClient"
        ],
        "initialization": {
          "azure_client": "azure_client = AsyncOpenAI(base_url='https://your-resource.openai.azure.com/openai/v1/', api_key='your-api-key')",
          "llm_client": "llm_client = AzureOpenAILLMClient(azure_client=azure_client, config=LLMConfig(model='gpt-4o', small_model='gpt-4o'))",
          "embedder": "embedder = AzureOpenAIEmbedderClient(azure_client=azure_client, model='text-embedding-3-small')"
        },
        "key_functions": [
          "AzureOpenAILLMClient(azure_client, config)",
          "AzureOpenAIEmbedderClient(azure_client, model)"
        ],
        "verified_against": "Context7 MCP: /getzep/graphiti"
      },
      "configuration": {
        "env_vars": [
          "AZURE_OPENAI_API_KEY",
          "AZURE_OPENAI_ENDPOINT (or AZURE_OPENAI_BASE_URL)",
          "AZURE_OPENAI_DEPLOYMENT (LLM deployment name)",
          "AZURE_OPENAI_EMBEDDING_DEPLOYMENT"
        ],
        "required_config": [
          "base_url (must end with /openai/v1/)",
          "api_key",
          "deployment names (not model names - these are your Azure deployment names)"
        ]
      },
      "gotchas": [
        "Azure uses deployment names, not model names - you must use your Azure deployment name",
        "The base_url MUST end with /openai/v1/ for the v1 API compatibility",
        "Uses the standard openai AsyncOpenAI client, not a separate Azure SDK",
        "May need separate Azure OpenAI clients for LLM and embeddings if they have different endpoints",
        "Azure OpenAI deployment must opt into the v1 API for structured outputs to work"
      ],
      "research_sources": [
        "Context7 MCP: /getzep/graphiti",
        "https://github.com/getzep/graphiti/blob/main/examples/azure-openai/"
      ]
    },
    {
      "name": "Ollama Provider",
      "type": "library_integration",
      "verified_package": {
        "name": "graphiti-core (base package)",
        "install_command": "pip install graphiti-core",
        "version": "included with graphiti-core",
        "verified": true
      },
      "api_patterns": {
        "imports": [
          "from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient",
          "from graphiti_core.llm_client.openai_client import OpenAIClient",
          "from graphiti_core.llm_client.config import LLMConfig",
          "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig"
        ],
        "initialization": {
          "llm_config": "llm_config = LLMConfig(api_key='ollama', model='deepseek-r1:7b', small_model='deepseek-r1:7b', base_url='http://localhost:11434/v1')",
          "llm_client": "llm_client = OpenAIGenericClient(config=llm_config)",
          "embedder": "embedder = OpenAIEmbedder(config=OpenAIEmbedderConfig(api_key='ollama', embedding_model='nomic-embed-text', embedding_dim=768, base_url='http://localhost:11434/v1'))"
        },
        "key_functions": [
          "OpenAIGenericClient(config=LLMConfig(...))",
          "OpenAIEmbedder(config=OpenAIEmbedderConfig(...))"
        ],
        "verified_against": "Context7 MCP: /getzep/graphiti, /ollama/ollama, /websites/help_getzep_graphiti"
      },
      "configuration": {
        "env_vars": [
          "OLLAMA_BASE_URL (default: http://localhost:11434/v1)",
          "OLLAMA_LLM_MODEL",
          "OLLAMA_EMBEDDING_MODEL",
          "OLLAMA_EMBEDDING_DIM"
        ],
        "default_values": {
          "base_url": "http://localhost:11434/v1",
          "llm_model": "deepseek-r1:7b",
          "embedding_model": "nomic-embed-text",
          "embedding_dim": 768
        }
      },
      "infrastructure": {
        "requires_docker": false,
        "local_installation": "curl -fsSL https://ollama.com/install.sh | sh",
        "model_pull_commands": [
          "ollama pull deepseek-r1:7b",
          "ollama pull nomic-embed-text"
        ],
        "start_command": "ollama serve",
        "test_command": "curl http://localhost:11434/v1/models"
      },
      "gotchas": [
        "Ollama uses OpenAI-compatible API at /v1 endpoint - use OpenAIGenericClient or OpenAIClient",
        "A dummy API key like 'ollama' or 'abc' is required even though Ollama ignores it",
        "MUST specify embedding_dim for Ollama embeddings (e.g., 768 for nomic-embed-text)",
        "Different embedding models have different dimensions - must be configured correctly",
        "Ollama must be running before Graphiti can connect",
        "Quality depends heavily on model choice - larger models = better results but slower"
      ],
      "embedding_dimensions": {
        "nomic-embed-text": 768,
        "mxbai-embed-large": 1024,
        "all-minilm": 384
      },
      "research_sources": [
        "Context7 MCP: /ollama/ollama",
        "Context7 MCP: /websites/help_getzep_graphiti",
        "https://github.com/ollama/ollama/blob/main/docs/api/openai-compatibility.mdx"
      ]
    },
    {
      "name": "Voyage AI Embeddings",
      "type": "library",
      "verified_package": {
        "name": "voyageai",
        "install_command": "pip install voyageai",
        "version": "latest (0.1.7+)",
        "verified": true,
        "graphiti_extra": "pip install graphiti-core[voyageai]"
      },
      "api_patterns": {
        "imports": {
          "standalone": [
            "import voyageai",
            "vo = voyageai.Client()"
          ],
          "graphiti_integration": [
            "from graphiti_core.embedder.voyage import VoyageEmbedder, VoyageAIConfig"
          ]
        },
        "initialization": {
          "standalone": "vo = voyageai.Client()  # Uses VOYAGE_API_KEY env var",
          "graphiti": "embedder = VoyageEmbedder(config=VoyageAIConfig(api_key='pa-...', embedding_model='voyage-3'))"
        },
        "key_functions": [
          "VoyageEmbedder(config=VoyageAIConfig(...))",
          "vo.embed(texts=['...'], model='voyage-3.5', input_type='document')"
        ],
        "verified_against": "Context7 MCP: /websites/voyageai, /getzep/graphiti"
      },
      "configuration": {
        "env_vars": ["VOYAGE_API_KEY"],
        "models_supported": [
          "voyage-3 (1024 dims, general purpose)",
          "voyage-3-lite (512 dims, faster)",
          "voyage-3.5 (standard)",
          "voyage-3.5-lite",
          "voyage-3-large (2048 dims)",
          "voyage-code-3 (code-optimized)",
          "voyage-finance-2 (finance-optimized)",
          "voyage-multimodal-3 (text + images)"
        ],
        "config_options": {
          "input_type": "'query' or 'document' - tailors embeddings for retrieval tasks",
          "truncation": "true/false - whether to truncate long inputs",
          "output_dimension": "optional dimension override for some models"
        }
      },
      "embedding_dimensions": {
        "voyage-3": 1024,
        "voyage-3-lite": 512,
        "voyage-3-large": 2048,
        "voyage-3.5": 1024,
        "voyage-code-3": 1024
      },
      "gotchas": [
        "Voyage is Anthropic's officially recommended embedding provider",
        "Different models have different dimensions - must match vector index configuration",
        "API key format starts with 'pa-' (not 'sk-')",
        "For graphiti-core integration, use: pip install graphiti-core[voyageai]",
        "VoyageAIConfig uses 'embedding_model' not 'model' as the parameter name"
      ],
      "research_sources": [
        "Context7 MCP: /websites/voyageai",
        "https://pypi.org/project/voyageai/",
        "https://docs.voyageai.com/docs/api-key-and-installation"
      ]
    },
    {
      "name": "OpenAI (Default Provider)",
      "type": "library_integration",
      "verified_package": {
        "name": "graphiti-core (base package)",
        "install_command": "pip install graphiti-core",
        "version": "included with graphiti-core",
        "verified": true
      },
      "api_patterns": {
        "imports": [
          "from graphiti_core.llm_client.openai_client import OpenAIClient",
          "from graphiti_core.llm_client.config import LLMConfig",
          "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig"
        ],
        "initialization": {
          "llm_client": "llm_client = OpenAIClient(config=LLMConfig(api_key='sk-...'))",
          "embedder": "embedder = OpenAIEmbedder(config=OpenAIEmbedderConfig(api_key='sk-...', embedding_model='text-embedding-3-small'))"
        },
        "key_functions": [
          "OpenAIClient(config=LLMConfig(...))",
          "OpenAIEmbedder(config=OpenAIEmbedderConfig(...))"
        ],
        "verified_against": "Context7 MCP: /getzep/graphiti"
      },
      "configuration": {
        "env_vars": ["OPENAI_API_KEY"],
        "default_models": {
          "llm": "gpt-4o",
          "embedding": "text-embedding-3-small"
        }
      },
      "embedding_dimensions": {
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072,
        "text-embedding-ada-002": 1536
      },
      "gotchas": [
        "OpenAI is the default provider if no other is specified",
        "Graphiti initializes with just OPENAI_API_KEY if using defaults",
        "The current project implementation only supports OpenAI - this PRD adds alternatives"
      ],
      "research_sources": [
        "Context7 MCP: /getzep/graphiti",
        "Current codebase: auto-claude/graphiti_config.py"
      ]
    }
  ],
  "unverified_claims": [
    {
      "claim": "PRD shows AzureOpenAIEmbedderClient import from graphiti_core.embedder.azure_openai",
      "verification_status": "verified",
      "actual_finding": "Import is correct: from graphiti_core.embedder.azure_openai import AzureOpenAIEmbedderClient",
      "risk_level": "low"
    },
    {
      "claim": "PRD shows AnthropicClient can be imported with LLMConfig from same module",
      "verification_status": "partially_verified",
      "actual_finding": "LLMConfig should be imported separately: from graphiti_core.llm_client.config import LLMConfig",
      "risk_level": "low"
    },
    {
      "claim": "Cross-encoder/reranker is required for Graphiti",
      "verification_status": "clarified",
      "actual_finding": "Cross-encoder is OPTIONAL but improves search quality. Default Graphiti works without it.",
      "risk_level": "low"
    }
  ],
  "recommendations": [
    "Use graphiti-core[falkordb,anthropic,voyageai] for full multi-provider support",
    "For Anthropic LLM users, recommend Voyage AI embeddings as the pairing (Anthropic's official recommendation)",
    "For Ollama, always specify embedding_dim in OpenAIEmbedderConfig - don't rely on defaults",
    "Consider adding cross-encoder support for improved search quality in future iteration",
    "Azure OpenAI users should be warned about the /openai/v1/ URL suffix requirement",
    "Add connection test functionality for each provider before saving settings"
  ],
  "provider_combinations": {
    "recommended": [
      {
        "name": "Default (OpenAI)",
        "llm": "openai",
        "embedder": "openai",
        "use_case": "Simple setup, good quality, single API key"
      },
      {
        "name": "Enterprise (Azure)",
        "llm": "azure_openai",
        "embedder": "azure_openai",
        "use_case": "Corporate compliance, data residency"
      },
      {
        "name": "Claude Stack",
        "llm": "anthropic",
        "embedder": "voyage",
        "use_case": "Consistency with Claude agents, Anthropic's recommendation"
      },
      {
        "name": "Fully Local",
        "llm": "ollama",
        "embedder": "ollama",
        "use_case": "Privacy, offline capability, zero API costs"
      }
    ],
    "valid_combinations": {
      "anthropic_llm_can_pair_with": ["openai", "voyage", "azure_openai", "ollama"],
      "ollama_llm_can_pair_with": ["openai", "voyage", "azure_openai", "ollama"],
      "note": "Any LLM provider can pair with any embedder provider"
    }
  },
  "context7_libraries_used": [
    "/getzep/graphiti",
    "/websites/help_getzep_graphiti",
    "/websites/voyageai",
    "/ollama/ollama"
  ],
  "created_at": "2025-12-12T15:05:00.000Z"
}
