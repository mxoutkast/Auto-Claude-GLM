{
  "feature": "Incorporate Human Review Before Coding",
  "workflow_type": "feature",
  "services_involved": ["auto-claude"],
  "phases": [
    {
      "phase": 1,
      "name": "Review Module Core",
      "type": "implementation",
      "depends_on": [],
      "parallel_safe": true,
      "chunks": [
        {
          "id": "chunk-1-1",
          "description": "Create review.py with ReviewState dataclass for persisting approval state",
          "service": "auto-claude",
          "files_to_create": ["auto-claude/review.py"],
          "files_to_modify": [],
          "patterns_from": ["auto-claude/linear_updater.py", "auto-claude/validate_spec.py"],
          "verification": {
            "type": "command",
            "run": "python -c \"from review import ReviewState; state = ReviewState(); print('ReviewState created:', state)\""
          },
          "status": "completed",
          "completed_at": "2025-12-12T15:05:00.000000",
          "implementation_details": "Create ReviewState dataclass with: approved (bool), approved_by (str), approved_at (str), feedback (list[str]), spec_hash (str for change detection). Include load() and save() methods following linear_updater.py pattern. Add is_approval_valid() method that compares spec_hash with current spec.md hash."
        },
        {
          "id": "chunk-1-2",
          "description": "Add display functions to show spec.md and implementation_plan.json summaries",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/review.py"],
          "files_to_create": [],
          "patterns_from": ["auto-claude/workspace.py", "auto-claude/ui.py"],
          "verification": {
            "type": "command",
            "run": "python -c \"from review import display_spec_summary, display_plan_summary; print('Display functions imported')\""
          },
          "status": "completed",
          "completed_at": "2025-12-12T15:15:00.000000",
          "implementation_details": "Add display_spec_summary(spec_dir) that extracts key sections from spec.md (Overview, Workflow Type, Files to Modify, Success Criteria). Add display_plan_summary(spec_dir) that shows phases, chunks count, and estimated work. Use box(), bold(), muted() from ui.py for formatting."
        },
        {
          "id": "chunk-1-3",
          "description": "Add review menu and user interaction functions",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/review.py"],
          "files_to_create": [],
          "patterns_from": ["auto-claude/workspace.py"],
          "verification": {
            "type": "command",
            "run": "python -c \"from review import ReviewChoice, get_review_menu_options; print('Review menu functions imported')\""
          },
          "status": "completed",
          "completed_at": "2025-12-12T16:30:00.000000",
          "implementation_details": "Create ReviewChoice enum (APPROVE, EDIT_SPEC, EDIT_PLAN, FEEDBACK, REJECT). Add get_review_menu_options() returning list of MenuOption objects. Add run_review_checkpoint(spec_dir) that displays summaries, shows menu, handles user choice, and returns ReviewState."
        }
      ]
    },
    {
      "phase": 2,
      "name": "Spec Runner Integration",
      "type": "implementation",
      "depends_on": [1],
      "parallel_safe": false,
      "chunks": [
        {
          "id": "chunk-2-1",
          "description": "Add --auto-approve flag to spec_runner.py CLI arguments",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/spec_runner.py"],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "run": "python auto-claude/spec_runner.py --help | grep -i auto-approve"
          },
          "status": "completed",
          "completed_at": "2025-12-12T17:45:00.000000",
          "implementation_details": "Add --auto-approve argument to argparse parser in main() function around line 1678. Set store_true action. Add description: 'Skip human review checkpoint and automatically approve spec for building'."
        },
        {
          "id": "chunk-2-2",
          "description": "Integrate review checkpoint into spec_runner.py after validation phase",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/spec_runner.py"],
          "files_to_create": [],
          "patterns_from": ["auto-claude/workspace.py"],
          "verification": {
            "type": "command",
            "run": "python -c \"from spec_runner import SpecOrchestrator; print('SpecOrchestrator imported')\""
          },
          "status": "completed",
          "completed_at": "2025-12-12T18:30:00.000000",
          "implementation_details": "In SpecOrchestrator.run() method, after phase_validation() completes successfully (around line 1580), add call to review checkpoint. Import from review module. If --auto-approve is set, skip review and auto-create approved state. Otherwise, call run_review_checkpoint(). If user rejects, return False. If user requests edit, open editor and loop back. Save ReviewState after approval."
        },
        {
          "id": "chunk-2-3",
          "description": "Modify spec_runner to only auto-start build when approved",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/spec_runner.py"],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "run": "grep -n 'run.py\\|--spec' auto-claude/spec_runner.py | head -5"
          },
          "status": "completed",
          "completed_at": "2025-12-12T19:45:00.000000",
          "implementation_details": "In main() around line 1745-1773, the auto-build launch only happens if not args.no_build. Add additional check: only launch if ReviewState.load(spec_dir).approved is True. If not approved, print message about needing to approve first with instructions."
        }
      ]
    },
    {
      "phase": 3,
      "name": "Run.py Integration",
      "type": "implementation",
      "depends_on": [1],
      "parallel_safe": true,
      "chunks": [
        {
          "id": "chunk-3-1",
          "description": "Add approval check in run.py before build starts",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/run.py"],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "run": "python -c \"from run import validate_environment; print('validate_environment imported')\""
          },
          "status": "completed",
          "completed_at": "2025-12-12T20:15:00.000000",
          "implementation_details": "In main() function, after validate_environment() check around line 615, add new check using ReviewState.load(spec_dir).is_approved(). If not approved, print error message with instructions on how to run review. Show: 'python auto-claude/spec_runner.py --spec {spec_name} --review' command. Exit with code 1."
        },
        {
          "id": "chunk-3-2",
          "description": "Add --force flag to run.py to bypass approval check",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/run.py"],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "run": "python auto-claude/run.py --help | grep -i force"
          },
          "status": "completed",
          "completed_at": "2025-12-12T20:30:00.000000",
          "implementation_details": "Add --force argument to parse_args() around line 416. Description: 'Skip approval check and start build anyway (for debugging)'. In the approval check added in chunk-3-1, if args.force is True, skip the check with a warning message."
        },
        {
          "id": "chunk-3-3",
          "description": "Add --review-status flag to show current review state",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/run.py"],
          "files_to_create": [],
          "patterns_from": ["auto-claude/qa_loop.py"],
          "verification": {
            "type": "command",
            "run": "python auto-claude/run.py --help | grep -i review"
          },
          "status": "completed",
          "completed_at": "2025-12-12T21:00:00.000000",
          "implementation_details": "Add --review-status argument to parse_args(). In main(), handle --review-status by calling display function from review.py that shows: approved status, when approved, by whom, any feedback, and whether spec has changed since approval."
        }
      ]
    },
    {
      "phase": 4,
      "name": "Edge Cases and Polish",
      "type": "implementation",
      "depends_on": [2, 3],
      "parallel_safe": false,
      "chunks": [
        {
          "id": "chunk-4-1",
          "description": "Add spec change detection to invalidate stale approvals",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/review.py"],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "run": "python -c \"from review import ReviewState; import hashlib; print('Hash imports work')\""
          },
          "status": "completed",
          "completed_at": "2025-12-12T15:30:00.000000",
          "implementation_details": "In ReviewState, implement spec_hash calculation using hashlib.md5 on spec.md content. When saving approval, store the hash. In is_approval_valid(), compare stored hash with current spec.md hash. If different, return False (approval is stale). Add re-approval flow when spec changes detected."
        },
        {
          "id": "chunk-4-2",
          "description": "Add editor integration for spec/plan editing during review",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/review.py"],
          "files_to_create": [],
          "patterns_from": ["auto-claude/spec_runner.py"],
          "verification": {
            "type": "command",
            "run": "python -c \"from review import open_file_in_editor; print('Editor function imported')\""
          },
          "status": "completed",
          "completed_at": "2025-12-12T22:00:00.000000",
          "implementation_details": "Add open_file_in_editor(filepath) function using os.environ.get('EDITOR', 'nano'). When user chooses EDIT_SPEC or EDIT_PLAN in review menu, open the appropriate file. After editor closes, re-display the summary and loop back to menu. Follow spec_runner.py _open_editor_for_input pattern (lines 777-819)."
        },
        {
          "id": "chunk-4-3",
          "description": "Add Ctrl+C graceful handling during review",
          "service": "auto-claude",
          "files_to_modify": ["auto-claude/review.py"],
          "files_to_create": [],
          "patterns_from": ["auto-claude/workspace.py"],
          "verification": {
            "type": "manual",
            "run": "Manual test: Run review and press Ctrl+C to verify graceful exit"
          },
          "status": "completed",
          "completed_at": "2025-12-12T22:30:00.000000",
          "implementation_details": "Wrap run_review_checkpoint in try/except for KeyboardInterrupt. On interrupt, save any feedback provided but do not mark as approved. Print message: 'Review paused. Your feedback has been saved. Run again to continue.'"
        }
      ]
    },
    {
      "phase": 5,
      "name": "Testing",
      "type": "implementation",
      "depends_on": [4],
      "parallel_safe": false,
      "chunks": [
        {
          "id": "chunk-5-1",
          "description": "Create unit tests for ReviewState",
          "service": "auto-claude",
          "files_to_create": ["tests/test_review.py"],
          "files_to_modify": [],
          "patterns_from": ["tests/test_security.py"],
          "verification": {
            "type": "command",
            "run": "pytest tests/test_review.py -v"
          },
          "status": "completed",
          "completed_at": "2025-12-12T23:45:00.000000",
          "implementation_details": "Create tests for: ReviewState load/save, is_approved() method, spec_hash calculation, is_approval_valid() with hash comparison. Use tmp_path fixture for spec directories. Test edge cases: missing review_state.json, corrupted JSON, spec changed after approval."
        },
        {
          "id": "chunk-5-2",
          "description": "Integration test for full review flow",
          "service": "auto-claude",
          "files_to_modify": ["tests/test_review.py"],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "run": "pytest tests/test_review.py::TestFullReviewWorkflowIntegration -v"
          },
          "status": "completed",
          "completed_at": "2025-12-12T15:45:00.000000",
          "implementation_details": "Test full flow: create mock spec directory with spec.md and implementation_plan.json, run review approval, verify review_state.json created, verify run.py would accept the build, modify spec.md, verify approval is invalidated."
        }
      ]
    }
  ],
  "final_acceptance": [
    "spec_runner.py pauses after validation phase and displays review prompt",
    "User can approve, edit, or reject the spec through CLI menu",
    "Approval state is persisted to review_state.json in spec directory",
    "run.py checks for approval before starting build (with clear error if not approved)",
    "--auto-approve flag allows skipping review for automated workflows",
    "Existing tests still pass",
    "Review UI is consistent with existing auto-claude UI patterns"
  ],
  "summary": {
    "total_phases": 5,
    "total_chunks": 13,
    "services_involved": ["auto-claude"],
    "parallelism": {
      "max_parallel_phases": 2,
      "parallel_groups": [
        {
          "phases": [2, 3],
          "reason": "Both depend only on phase 1, modify different files"
        }
      ],
      "recommended_workers": 2,
      "speedup_estimate": "1.4x faster than sequential"
    },
    "startup_command": "source auto-claude/.venv/bin/activate && python auto-claude/run.py --spec 005 --parallel 2"
  },
  "qa_acceptance": {
    "unit_tests": {
      "required": true,
      "commands": ["pytest tests/test_review.py -v"],
      "minimum_coverage": null
    },
    "integration_tests": {
      "required": true,
      "commands": ["pytest tests/test_review.py -v"],
      "services_to_test": ["auto-claude"]
    },
    "e2e_tests": {
      "required": false,
      "commands": [],
      "flows": []
    },
    "browser_verification": {
      "required": false,
      "pages": []
    },
    "database_verification": {
      "required": false,
      "checks": []
    },
    "manual_verification": {
      "required": true,
      "checks": [
        "Run spec_runner.py with --task and verify review prompt appears after spec creation",
        "Verify approve/edit/reject options work correctly",
        "Verify run.py blocks when spec is not approved",
        "Verify --auto-approve flag skips review",
        "Verify Ctrl+C during review saves feedback and exits gracefully"
      ]
    }
  },
  "qa_signoff": {
    "status": "approved",
    "timestamp": "2025-12-12T16:00:00.000000",
    "qa_session": 1,
    "report_file": "qa_report.md",
    "tests_passed": {
      "unit": "63/63",
      "integration": "included in unit",
      "e2e": "N/A"
    },
    "verified_by": "qa_agent"
  },
  "created_at": "2025-12-12T15:00:00.000000",
  "updated_at": "2025-12-12T15:00:00.000000",
  "spec_file": "/Users/andremikalsen/Documents/Coding/autonomous-coding/.auto-claude/specs/005-incoporate-human-review-before-coding/spec.md"
}
